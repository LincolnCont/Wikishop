#!/usr/bin/env python
# coding: utf-8

# <h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class="tocSkip"></span></h1>
# <div class="toc"><ul class="toc-item"><li><span><a href="#–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞" data-toc-modified-id="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞</a></span></li><li><span><a href="#–û–±—É—á–µ–Ω–∏–µ" data-toc-modified-id="–û–±—É—á–µ–Ω–∏–µ-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>–û–±—É—á–µ–Ω–∏–µ</a></span><ul class="toc-item"><li><span><a href="#–õ–æ–≥–∏—á—Å—Ç–∏—á–µ—Å–∫–∞—è-—Ä–µ–≥—Ä–µ—Å—Å–∏—è" data-toc-modified-id="–õ–æ–≥–∏—á—Å—Ç–∏—á–µ—Å–∫–∞—è-—Ä–µ–≥—Ä–µ—Å—Å–∏—è-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>–õ–æ–≥–∏—á—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è</a></span></li><li><span><a href="#–î–µ—Ä–µ–≤–æ-—Ä–µ—à–µ–Ω–∏–π" data-toc-modified-id="–î–µ—Ä–µ–≤–æ-—Ä–µ—à–µ–Ω–∏–π-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π</a></span></li><li><span><a href="#C–ª—É—á–∞–π–Ω—ã–π-–ª–µ—Å" data-toc-modified-id="C–ª—É—á–∞–π–Ω—ã–π-–ª–µ—Å-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>C–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å</a></span></li><li><span><a href="#LightGBM" data-toc-modified-id="LightGBM-2.4"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href="#XGBoost" data-toc-modified-id="XGBoost-2.5"><span class="toc-item-num">2.5&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href="#–ê–Ω–∞–ª–∏–∑-–ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö-–º–µ—Ç—Ä–∏–∫-–∏-–≤—ã–±–æ—Ä-–º–æ–¥–µ–ª–∏:" data-toc-modified-id="–ê–Ω–∞–ª–∏–∑-–ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö-–º–µ—Ç—Ä–∏–∫-–∏-–≤—ã–±–æ—Ä-–º–æ–¥–µ–ª–∏:-2.6"><span class="toc-item-num">2.6&nbsp;&nbsp;</span>–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏:</a></span></li></ul></li><li><span><a href="#–í—ã–≤–æ–¥—ã" data-toc-modified-id="–í—ã–≤–æ–¥—ã-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>–í—ã–≤–æ–¥—ã</a></span></li><li><span><a href="#–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏" data-toc-modified-id="–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>–ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏</a></span></li></ul></div>

# # –ü—Ä–æ–µ–∫—Ç –¥–ª—è ¬´–í–∏–∫–∏—à–æ–ø¬ª

# –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é. 
# 
# –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –í –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.
# 
# –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75. 
# 
# **–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞**
# 
# 1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.
# 2. –û–±—É—á–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. 
# 3. –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã.
# 
# –î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å *BERT* –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å.
# 
# **–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**
# 
# –î–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ñ–∞–π–ª–µ `toxic_comments.csv`. –°—Ç–æ–ª–±–µ—Ü *text* –≤ –Ω—ë–º —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –∞ *toxic* ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫.

# ## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞

# In[1]:



import pandas as pd
import matplotlib.pyplot as plt 
plt.style.use('seaborn-pastel')
import seaborn as sns 
import numpy as np 
import warnings
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords as nltk_stopwords
from nltk.corpus import wordnet
from nltk.tokenize import word_tokenize


import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import RandomizedSearchCV
import lightgbm as lgb
import xgboost as xgb
from sklearn.metrics import f1_score

from time import time
from tqdm import tqdm

pd.options.display.max_columns = None
warnings.filterwarnings("ignore")


# In[ ]:





# 
# <div class="alert alert-success">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –£—Å–ø–µ—Ö:
# 
# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –ª–µ–≥—á–µ –±—ã–ª–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∏ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏. 
# 
#  
# <div class="alert alert-warning">
# 
# 
# –°–æ–≤–µ—Ç:
# 
#     
#     
# - —É —Ç–µ–±—è —Ç—É—Ç –µ—Å—Ç—å –ª–∏—à–Ω–∏–µ –∏–º–ø–æ—Ä—Ç—ã, —Ç–æ —á—Ç–æ —Ç—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –Ω–µ –≤–µ—Ä–Ω–æ - —Å—Ç–æ–∏—Ç —É–±—Ä–∞—Ç—å, —á—Ç–æ–±—ã –ø–æ–±–µ—Ä–µ—á—å —Ä–µ—Å—É—Ä—Å—ã      
#  
#  
#  
# 
# - –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ PEP-8 –ø—Ä–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ –∫–æ–¥–∞, –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤. –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –º–æ–∂–µ—à—å –ø–æ—á–∏—Ç–∞—Ç—å [—Ç—É—Ç](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html). –ï—Å—Ç—å —á—Ç–æ –ø–æ–ø—Ä–∞–≤–∏—Ç—å 
# 
# 

# In[19]:


nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

stopwords = set(nltk_stopwords.words('english'))


# In[20]:


df = pd.read_csv('/datasets/toxic_comments.csv')
df.head()


# <div class="alert alert-warning">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –°–æ–≤–µ—Ç: 
# 
# 
# –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å - —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Å—Ç–æ–ª–±—Ü–∞  `Unnamed: 0` –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –º–æ–∂–Ω–æ —Ç–∞–∫:
# 
# 
#     pd.read_csv(..., index_col=0)
# 
#     
# (`Unnamed: 0` –ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –Ω–µ —Å–æ–≤—Å–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞)    
# 
# 
# Unnamed: 0 —ç—Ç–æ "—Å–ª–µ–¥" —Å—Ç–∞—Ä—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤. –ï—Å–ª–∏ —Ç—ã —É–±–µ—Ä—ë—à—å –ø–µ—Ä–≤—ã–µ 10 –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ —Å–≤–æ–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, —Å–æ—Ö—Ä–∞–Ω–∏—à—å –µ–≥–æ, –∞ –ø–æ—Ç–æ–º –æ—Ç–∫—Ä–æ–µ—à—å,  —Ç–æ –ø–æ—è–≤–∏—Ç—Å—è —Å—Ç–æ–ª–±–µ—Ü Unnamed: 0 –Ω–∞—á–∏–Ω–∞—è —Å —Ü–∏—Ñ—Ä—ã 9, –∏ –ø–æ—è–≤–∏—Ç—Å—è –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å—ã –Ω–∞—á–∏–Ω–∞—è —Å –Ω—É–ª—è 
# 
# 
# –ù–æ —ç—Ç–æ –º–µ–ª–æ—á—å,  –¥–∞–∂–µ –Ω–µ –Ω—É–∂–Ω–æ –Ω–∏—á–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å. –ü—Ä–æ—Å—Ç–æ –∑–Ω–∞–π, —á—Ç–æ–±—ã —É–≤–∏–¥–µ–≤ —Ç–∞–∫–æ–µ –≤ —á—É–∂–æ–º –∫–æ–¥–µ –Ω–µ —É–¥–∏–≤–ª—è—Ç—å—Å—è —á—Ç–æ –±—ã —ç—Ç–æ –º–æ–≥–ª–æ –æ–∑–Ω–∞—á–∞—Ç—å

# In[21]:


df.info()


# –°–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫ –¥–∞–Ω–Ω—ã–º, c—Ç–æ–ª–±–µ—Ü text —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –∞ toxic ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫.
# 

# In[22]:


df.isna().sum()


# In[23]:


df['text'].duplicated().sum()


# –í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
# 
# –ò–∑—É—á–∏–º —Å–±–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö

# In[24]:


df['toxic'].hist()


# <div class="alert alert-warning">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –°–æ–≤–µ—Ç ü§î:
# 
# 
# - –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É–±—Ä–∞—Ç—å <AxesSubplot:>.  —Ç–æ —Å—Ç–∞–≤—å –≤ –∫–æ–Ω—Ü–µ `;` –∏–ª–∏ –ø—Ä–æ–ø–∏—à–∏ plt.show()
# 
# - –ù–µ   –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É

# –î–∞–Ω–Ω—ã–µ –∏–º–µ–µ—é—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å.
# 
# –°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –æ—á–∏—Å—Ç–∏—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –±—É–¥—É—â–µ–π –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏:

# <div class="alert alert-success">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –£—Å–ø–µ—Ö:
# 
#  
#     
# 
# -  –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å 
# 
# 
# 
# - –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Ü–µ —Ä–∞–∑–¥–µ–ª–∞
# 
#  
# 
# <div class="alert alert-warning">
# 
# –°–æ–≤–µ—Ç: 
# 
# 
#  
# 
# - –º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –ø–æ—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π,  –¥–ª–∏–Ω—É —Å–ª–æ–≤ –≤ —Ç–≤–∏—Ç–µ, –æ–ø—è—Ç—å –∂–µ –≤ —Ä–∞–∑–±–∏–≤–∫–µ –ø–æ –¢–∞—Ä–≥–µ—Ç—É.  –ï—Å–ª–∏ –±—É–¥—É—Ç –∫–∞–∫–∏–µ-—Ç–æ —Å–∏–ª—å–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è, –≤–æ–∑–º–æ–∂–Ω–æ –∏–∑-–∑–∞ —ç—Ç–æ–≥–æ —Å—Ç–æ–∏—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –Ω–∞—à–∏—Ö –º–æ–¥–µ–ª–µ–π. –ò–ª–∏ –Ω–∞–ø—Ä–∏–º–µ—Ä –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É SentimentIntensityAnalyzer –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∞–Ω—Ç–∏–º–µ–Ω—Ç–æ–≤, –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –µ–µ –æ—Ü–µ–Ω–∫–∏ –∫–æ—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –Ω–∞—à–∏–º–∏ —Ç–∞—Ä–≥–µ—Ç–∞–º–∏
#    
#    
# - –∫–æ–≥–¥–∞ –º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Å —Ç–µ–∫—Å—Ç–∞–º–∏, describe –∏—Ç–ø –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –Ω–æ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞.  –ü—Ä–µ–¥–ª–∞–≥–∞—é –¥–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [–æ–±–ª–∞–∫–æ —Å–ª–æ–≤](https://habr.com/ru/post/517410/) - —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ–±—â–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–µ–º–∞—Ç–∏–∫–µ –∏ –æ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ–º—ã—Ö —Å–ª–æ–≤–∞—Ö –≤ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∏ –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Ç–≤–∏—Ç–∞—Ö (–≤ –æ–±–ª–∞–∫–µ —É–∂–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±—É–¥—É—Ç —É–±—Ä–∞–Ω—ã —Å—Ç–æ–ø —Å–ª–æ–≤–∞). –ö—Ä–æ–º–µ —Ç–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∏, —Ä–∏—Å—É–Ω–∫–∏ –¥–µ–ª–∞—é—Ç –ø—Ä–æ–µ–∫—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–µ–π
#    
#    
# –í —Ç—Ä–µ–Ω–∞–∂–µ—Ä–µ –æ–±–ª–∞–∫–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–∞–∫
# 
#     !/opt/conda/bin/python -m pip install wordcloud 
# 
# 
# –∏–ª–∏
# 
#     !/opt/conda/bin/python -m pip install wordcloud==1.8.2.2  
# 
# 
# –ò –≤–æ–∑–º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –Ω–∞–¥–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞—Ç—å
# 
# 
# 
#     !pip install --upgrade Pillow  (–ø–æ–ø—Ä–æ–±—É–π –≤–µ—Ä—Å–∏—é 9.5.0)
# 
#   
# 

# In[25]:


def clear_text(text):
    text = re.sub(r'[^a-zA-Z ]', ' ', text.lower()) 
    retext = text.split() 
    text = " ".join(retext)
    return text


# –°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ç–æ–µ–∫–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:

# In[ ]:





# In[27]:


def get_wordnet_pos(word):
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ,
                "N": wordnet.NOUN,
                "V": wordnet.VERB,
                "R": wordnet.ADV}
    return tag_dict.get(tag, wordnet.NOUN)


# In[28]:


nltk.download('stopwords')
stopwords = set(nltk_stopwords.words('english'))


# In[29]:


lemmatizer = WordNetLemmatizer()


# In[30]:


def lemmetize(text):
    
    token = nltk.word_tokenize(text)
    text = [word for word in token if word not in stopwords]
    text = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text])
    
    return text


# <span style="background-color: #FFFF00">–°–¥–µ–ª–∞–ª –∏ –ø—Ä–æ–≤–µ—Ä–∏–ª –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑ 10 —Å—Ç—Ä–æ–∫</span>
# 
# 

# In[31]:





# –í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

# In[32]:


df['lemm_text'] = df['text'].apply(clear_text)
df['lemm_text'] = df['lemm_text'].apply(lemmetize)

df['lemm_text']


# <div class="alert alert-success">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –£—Å–ø–µ—Ö:
# 
# 
#  
# - –ü–ª—é—Å –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ apply, –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Ü–∏–∫–ª—ã –Ω–∞–º –Ω–∏ –∫ —á–µ–º—É.
# 
# 
# - –î–∞, –≤—Å–µ–≥–¥–∞ –ª—É—á—à–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å  –≤ –∏—Ç–æ–≥–µ, —Ç–∞–∫ –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É
# 
# <div class="alert alert-warning">
# 
# 
# –°–æ–≤–µ—Ç: 
# 
# 
#     
# - –ø–æ–ø—Ä–æ–±—É–π .progress_apply, –¥–µ–ª–∞–µ—Ç —á—Ç–æ .apply, –Ω–æ –µ—â–µ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–∞–∫–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø—Ä–æ—Ü–µ—Å—Å.  
# 
# –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏–π, —á—Ç–æ–±—ã –∑–∞—Ä–∞–±–æ—Ç–∞–ª .progress_apply –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:
#     
#     
#     from tqdm.notebook import tqdm
#     tqdm.pandas()
#     
# 
# –ò c—É–¥—è –ø–æ –≤—Å–µ–º—É –∏–º–ø–æ—Ä—Ç—ã –Ω—É–∂–Ω–æ –∑–∞—Å—É–Ω—É—Ç—å –≤–Ω—É—Ç—Ä—å —Ñ—É–Ω–∫—Ü–∏–∏
# 
# –¢–æ –∂–µ —Å–∞–º–æ–µ –¥–µ–ª–∞–µ—Ç .swifter.apply  –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ
# 
# 
#     !pip install swifter
#     import swifter
# 
# 
# 
# - –µ—Å–ª–∏  –ø—Ä–æ—Ü–µ—Å—Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å [.parallel_apply](https://pypi.org/project/pandarallel/), –¥–ª—è WordNetLemmatizer —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ—á–Ω–æ (–¥–ª—è spacy —É –º–µ–Ω—è –Ω–µ –ø–æ–ª—É—á–ª–æ—Å—å, –Ω–æ —Ç–∞–º –µ—Å—Ç—å —Å–≤–æ—è, –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å—Ö–µ–º–∞ –ø–∞—Ä–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å—á—ë—Ç–æ–≤ —á–µ—Ä–µ–∑ pipline). –ö–æ–º—É-—Ç–æ —ç—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å –≤—Ä–µ–º—è –ø—Ä–æ–≥–æ–Ω–∞ –∫–æ–¥–∞ —Ä–∞–∑ –≤ 5-7 (–•–æ—Ç—è —Å—Ç—É–¥–µ–Ω—Ç—ã –Ω–∞—á–∏–Ω–∞—é—Ç –∂–∞–ª–æ–≤–∞—Ç—å—Å—è —á—Ç–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –¥–∞–∂–µ –º–µ–¥–ª–µ–Ω–Ω–µ–µ). –ù–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ç–æ–∏—Ç

# –ß—Ç–æ–±—ã –∞–ª–≥–æ—Ä–∏—Ç–º—ã —É–º–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–µ–º–∞—Ç–∏–∫—É –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, –∏—Ö –Ω—É–∂–Ω–æ –æ–±—É—á–∏—Ç—å –Ω–∞ –∫–æ—Ä–ø—É—Å–µ (–∞–Ω–≥–ª. corpus). –≠—Ç–æ –Ω–∞–±–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä–æ–º —ç–º–æ—Ü–∏–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —É–∂–µ —Ä–∞–∑–º–µ—á–µ–Ω—ã.
# 
# –†–∞–∑–¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ç–µ—Å—Ç–æ–≤—É—é –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –≤—ã–±–æ—Ä–∫—É, —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ - 20% –æ—Ç –æ–±—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö:

# In[14]:


train_features, test_features, train_target, test_target = train_test_split(
    df.drop('toxic', axis=1),
    df['toxic'],
    test_size=0.2,
    random_state=12345,
    stratify=df['toxic'] 
)


corpus_train = train_features['lemm_text']
corpus_test = test_features['lemm_text']
corpus_train


# –í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è TfidfVectorizer –∏, —á—Ç–æ–±—ã –ø–æ—á–∏—Å—Ç–∏—Ç—å –º–µ—à–æ–∫ —Å–ª–æ–≤, –¥–æ–±–∞–≤–∏–º –≤ –Ω–µ–≥–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞:

# In[15]:


count_tf_idf = TfidfVectorizer(stop_words=stopwords) 
tf_idf_train = count_tf_idf.fit_transform(corpus_train) 
tf_idf_test = count_tf_idf.transform(corpus_test) 

print("–†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã:", tf_idf_train.shape)
print("–†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã:", tf_idf_test.shape)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, TF-IDF –ø–æ–¥—Å—á–∏—Ç–∞–Ω–æ, –º–æ–∂–Ω–æ –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏:

# ## –û–±—É—á–µ–Ω–∏–µ

# –í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:
# 
# - –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
# - –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π
# - –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
# - –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥
# 
# –°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –æ–±—É—á–∏—Ç –∏ –≤–µ—Ä–Ω–µ—Ç –º–æ–¥–µ–ª—å, –∞ —Ç–∞–∫ –∂–µ –∑–∞–ø–æ–ª–Ω–∏—Ç —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫:

# In[16]:



analisys = pd.DataFrame({'model':[], 'F1_model':[], 'F1_on_train':[]})
all_models = []


def train_model(model, parameters):
    
    model_random = RandomizedSearchCV(
        estimator=model,
        param_distributions=parameters,
        scoring='f1', 
        n_jobs=-1,
        cv=4, 
        verbose=2
        random_state=45
    )
    
   
    start = time()
    model_random.fit(tf_idf_train, train_target)
    print('RandomizedSearchCV –ø–æ–¥–±–∏—Ä–∞–ª –ø–∞—Ä–∞–º–µ—Ç—Ä—ã %.2f —Å–µ–∫—É–Ω–¥' %(time() - start))
    
   
    f1 = model_random.best_score_
    f1_on_train = f1_score(train_target, model_random.predict(tf_idf_train))
    
    print('–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:', model_random.best_params_)
    print('F1 –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:', f1)
    print('F1 –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ:', f1_on_train)

     
    all_models.append(model_random)
    row = []
    row.extend([model, f1, f1_on_train])
    analisys.loc[len(analisys.index)] = row
    
    return model_random


# <div class="alert alert-success">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –£—Å–ø–µ—Ö:
# 
# 
# 
# 
# 
# 
# –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω RandomizedSearchCV. –ï—Å—Ç—å –∏ –¥—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã, —Ç—é–Ω–∏–Ω–≥–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –º–æ–∂–µ—à—å [–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è](https://www.freecodecamp.org/news/hyperparameter-optimization-techniques-machine-learning/). –í—ã–¥–µ–ª—é –æptuna, –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –ø–ª—é—Å–æ–≤, –ø—Ä–∏—á–µ–º –∏–∑—É—á–µ–Ω–∏–µ –º–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å [**OptunaSearchCV**](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.OptunaSearchCV.html). –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ —É GridSearchCV, –ø–æ—ç—Ç–æ–º—É –æ—á–µ–Ω—å –ª–µ–≥–∫–æ –Ω–∞—á–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è
# 
#  
# 
#  
# 
# 
#     
# 
# <div class="alert alert-warning">
# 
# 
# 
# 
# 
# –°–æ–≤–µ—Ç: 
# 
#  
# –ú–æ–ª–æ–¥–µ—Ü —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å GridSearch, –Ω–æ –µ—â–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤—è–∑–∫—É GridSearchCV/RandomizedSearchCV + pipeline. 
# 
# 
# –û pipeline:
# 
# [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), —ç—Ç–æ —Ç–µ–º–∞ –∫–æ—Ç–æ—Ä–∞—è —Å—Ä–∞–∑—É –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—é, —Ç—é–Ω–∏–Ω–≥ "–≤–µ–∫—Ç–æ—Ä–∞–π–∑", –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –∏ –æ —Ç–æ–º —á—Ç–æ –∫–æ–¥ —Å—Ç–æ–∏—Ç –¥–µ–ª–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º.
#     
#     
# - –≤ TfidfVectorizer(stop_words=stopwords) —É —Ç–µ–±—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ngram_range=(1, 1), —Ç—É—Ç –º–æ–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å —Ä–∞–∑–Ω–æ–µ —á–∏—Å–ª–æ n- –≥—Ä–∞–º–º (–∏ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã), –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—è –º–µ—Ç—Ä–∏–∫—É, –Ω–æ –∫–∞–∫ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –ø–µ—Ä–µ–±–æ—Ä –ø–æ ngram_range —Å –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ü–∏–∫–ª–∞?! pipeline! –ì–æ—Ç–æ–≤—ã–π [–ø—Ä–∏–º–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–∞–º–∏](https://medium.com/@yoni.levine/how-to-grid-search-with-a-pipeline-93147835d916). –í—Å—ë —á—Ç–æ –Ω—É–∂–Ω–æ —Ç–∞–º –µ—Å—Ç—å, —Ö–æ—Ç—è –æ—á–µ–Ω—å –ª–∞–∫–æ–Ω–∏—á–Ω–æ. –ú–æ–∂–µ—à—å –ø–æ–≥—É–≥–ª–∏—Ç—å –ø–æ:
# 
# 
#     
#     pipeline nlp gridsearchcv
# 
# 
# 
# - –∫–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ –ø–æ–¥–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ, –∫–æ–≥–¥–∞ –º—ã –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏ (—à–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, TfidfVectorizer –∏—Ç–ø –∏—Ç–¥)? pipeline! –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ç–æ –≤–∞–∂–Ω–æ, –∫–æ–≥–¥–∞ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—é. –î–ª—è TfidfVectorizer –¥–µ–ª–∞–µ–º .fit (–æ–±—É—á–∞–µ–º—Å—è) –Ω–∞ train, –∞ transform –Ω–∞ test, –Ω–æ —Ç–æ—á–Ω–æ —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏. –ù–æ GS –¥–µ–ª–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–Ω—É—Ç—Ä–∏ —Å–µ–±—è, —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ –¥–æ–±—Ä–∞—Ç—å—Å—è –¥–æ –Ω–µ–µ –∏ –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–¥–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ? –ö–∞–∑–∞–ª–æ—Å—å –±—ã –Ω–∏–∫–∞–∫, –Ω–æ –Ω–µ—Ç! Pipeline! ) 
#     
#     
# - pipeline –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ–ª–∞—Ç—å –Ω–∞—à –∫–æ–¥ –∫–æ–º–ø–∞–∫—Ç–Ω–µ–π –∏ —á–∏—Ç–∞–±–µ–ª—å–Ω–µ–π, —ç—Ç–æ –±–æ–ª—å—à–æ–π –ø–ª—é—Å, –∫–æ–≥–¥–∞ –∫–æ–¥ –±—É–¥–µ—Ç —Ä–∞–∑–¥—É–≤–∞—Ç—å—Å—è     
#     
#     
# 
#          
# –ï—Å–ª–∏ —Ä–∞–Ω—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª pipeline —Ç–æ –º–æ–≥—É –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ –≤ –∫–æ—Ç–æ—Ä–æ–º [–∏–Ω–¥—É—Å](https://www.youtube.com/watch?v=mOYJCR0IDk8&ab_channel=HimanshuChandra) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å —Å–∏–ª—å–Ω—ã–º –∞–∫—Ü–µ–Ω—Ç–æ–º, –Ω–æ –Ω–∞ –ø–∞–ª—å—Ü–∞—Ö –æ–±—å—è—Å–Ω—è–µ—Ç  —Å–∞–º–æ–µ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–µ (–ø–æ –º–æ–µ–º—É –æ–ø—ã—Ç—É): —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤ fit –∏ transform. –¢–∞–º –∂–µ –µ—Å—Ç—å –∏ –∫–æ–¥ –∏ —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–µ–∫—Å—Ç. –ú–Ω–µ –ø–æ–º–æ–≥–ª–æ )
# 
# 
# 
# –í –æ–±—â–µ–º –µ—Å–ª–∏ —Å–¥–µ–ª–∞—Ç—å RS+pipeline –±—É–¥–µ—Ç –≤–æ–æ–±—â–µ —Ö–æ—Ä–æ—à–æ )  
#     
# <div>   

# ### –õ–æ–≥–∏—á—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è

# In[17]:


ran_lr = {
    "penalty": ['l1', 'l2', 'elasticnet', 'none'],
    "class_weight": ['balanced', 'none'],
}

logr = LogisticRegression(max_iter=300)

lr_random = train_model(logr, ran_lr)


# ### –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π 

# In[18]:


ran_grid_tree = {
    "max_depth": list(range(45, 56))
}

dtr = DecisionTreeClassifier()

dtr_random = train_model(dtr, ran_grid_tree)


# ### C–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å 

# In[19]:


ran_grid_forest = {
    'max_depth': [300, 310],
    'n_estimators': [12, 14],
}

rfc = RandomForestClassifier(n_jobs=-1)

rfc_random = train_model(rfc, ran_grid_forest)


# ### LightGBM

# In[20]:


rand_lgbm_param = {
    'max_depth': [15, 25],
    'learning_rate': [0.1, 0.3]
}

gbm = lgb.LGBMClassifier(
    boosting_type='gbdt',
    n_jobs=-1
)

gbm_random= train_model(gbm, rand_lgbm_param)


# ### XGBoost

# In[21]:


rand_xgb_param = {
    'max_depth': [6, 7, 8, 9],
    'learning_rate': [0.5, 1.0]
}

xb = xgb.XGBClassifier(booster='gbtree', 
                      use_rmm=True,
                      n_jobs=-1)

xb_random = train_model(xb, rand_xgb_param)


# ### –ê–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏:

# In[22]:


all_names = pd.DataFrame({'names':[ 'LogisticRegression', 'DecisionTree', 'RandomForest', 'LightGBM', 'XGBoost']})
analisys = pd.concat([analisys, all_names], axis=1, join='inner')
display(analisys)

analisys.plot.bar(y='F1_model', x='names', rot=45, figsize=(15,7), color='orange')
plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π', fontsize='x-large')
plt.xlabel('–ú–æ–¥–µ–ª—å')
plt.show()

analisys.plot.bar(y='F1_on_train', x='names', rot=45, figsize=(15,7), color='green')
plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ', fontsize='x-large')
plt.xlabel('–ú–æ–¥–µ–ª—å')
plt.show()


# –ò—Å—Ö–æ–¥—è –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π, –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –Ω–∞ RandomizedSearchCV - LightGBM c –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ max_depth: 25, learning_rate: 0.3. –ù–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ, –ª—É—á—à—É—é –º–µ—Ç—Ä–∏–∫—É –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –°–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞, –Ω–æ –∏ —Ö—É–¥—à—É—é –Ω–∞ –ø–æ–¥–±–æ—Ä–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ç–æ –µ—Å—Ç—å –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ –∏ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω—É–∂–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.

# <div class="alert alert-success">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# 
# 
# –£—Å–ø–µ—Ö üëç:
# 
# 
# 
# –ù–∞–≥–ª—è–¥–Ω–æ. 
#     
# (–í–æ–æ–±—â–µ –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å –Ω–µ —Å–∫–ª–æ–Ω–µ–Ω –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é,  –î–∞–∂–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ—á–µ–º—É —Ç–∞–∫ –ø–æ–ª—É—á–∏–ª–æ—Å—å)
# 
# 
#  

# ## –í—ã–≤–æ–¥—ã

# In[23]:


predicted = xb_random.predict(tf_idf_test)
print('F1 –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:', f1_score(test_target, predicted))


# <div class="alert alert-success">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# –£—Å–ø–µ—Ö: 
# 
# - –í—Å–µ –≤–µ—Ä–Ω–æ, –ª–æ–≥–∏–∫–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –Ω–∞—Ä—É—à–µ–Ω–∞, —Ç—É—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –æ—Ç–æ–±—Ä–∞–Ω–Ω—É—é –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –∏–ª–∏ –ø–∞—Ä–æ—á–∫—É –ª—É—á—à–∏—Ö, –µ—Å–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–∏–∑–∫–∏
# 
#  
# 
# - –ï—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª –Ω–∞ —Ç–µ—Å—Ç–µ f1 –≤—ã—à–µ 0,75, —ç—Ç–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—Ä–∏–µ–º–ª–µ–º—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º.
# 
# 
# <div class="alert alert-warning">
# 
# 
# 
# –°–æ–≤–µ—Ç: 
# 
#  
# 
# 
# - –º–æ–∂–Ω–æ –ø–æ–∏–≥—Ä–∞—Ç—å—Å—è [–ø–æ—Ä–æ–≥–æ–º](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/). –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º–æ–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å –º–µ—Ç—Ä–∏–∫—É –Ω–∞ –ø—Ä–æ—Ü–µ–Ω—Ç - –ø–æ–ª—Ç–æ—Ä–∞
#    
# 
#  
#     
#  
# 
#     
#  - –ø–æ–ª–µ–∑–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä—ã  (—Ç—É—Ç –ø—Ä–∏–≥–æ–¥–∏—Ç—Å—è pipeline). –≠—Ç–æ –∫–æ–Ω–µ—á–Ω–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ—â–Ω–æ—Å—Ç–µ–π, –≤–µ–¥—å –µ—Å–ª–∏ –¥–∞–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–≥—Ä–∞–º–º—ã —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–∑–∫–æ —É–≤–µ–ª–∏—á–∏—Ç—Å—è
# 
# 
#       
# 
#     
# - –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏. –ø—Ä–æ–µ–∫—Ç —Å–≤–æ–µ–æ–±—Ä–∞–∑–Ω—ã–π –≤—ã–±–æ—Ä –º–µ–∂–¥—É –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ (–º–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤, —Ä–∞—Å—á–µ—Ç—ã –º–æ–≥—É—Ç –∑–∞—Ç—è–Ω—É—Ç—å—Å—è) –∏ –∑–∞–¥–∞—á–µ–π –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ä–æ—à—É—é –º–µ—Ç—Ä–∏–∫—É. –° —ç—Ç–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è  –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è [–º–æ–¥–µ–ª—å–∫–∞](https://medium.com/geekculture/passive-aggressive-algorithm-for-big-data-models-8cd535ceb2e6) (–æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é VPN) [–∏–ª–∏](https://datafinder.ru/products/passivno-agressivnyy-klassifikator-v-mashinnom-obuchenii). –û–Ω–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—á–µ–Ω—å —à—É—Å—Ç—Ä–æ–π     
#     
# 
# 
# - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –ë–µ—Ä—Ç–∞, –≤—ã–±—Ä–∞–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å –∏ –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏, –¥–∞–∂–µ –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞ test –ø–æ–∫–∞–∂–µ—Ç —Ö–æ—Ä–æ—à—É—é –º–µ—Ç—Ä–∏–∫—É. –í —ç—Ç–æ–º —Å–ª—É—á–∞–∏ –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É > 0.95 (–ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏)
# 
# 
# 

# 
# 
# 
# <div class="alert alert-warning">
# <font size="5"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>
# 
# 
# –°–æ–≤–µ—Ç: 
# 
# 
# –ê –µ—â—ë –º–æ–∂–µ—à—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞  —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤    
#     
#     
#     
#     .get_feature_names_out().tolist()
#     
#     
#     
# –ü–æ–ª—É—á–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤–∞–∂–Ω–æ—Å—Ç–∏ (–¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)    
#     
#     .coef_.tolist()[0]
# 
# 
# 
# 
#  
# 
# –ê –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ç–∞–∫–æ–π-—Ç–æ –∫—Ä–∞—Å–∏–≤—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å –ø–æ–º–æ—â—å—é     seaborn
# 
# 

# –í –¥–∞–Ω–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—ã–ª–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ F1 - 0.75.
# 
# –ù–∞ —ç—Ç–∞–ø–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫–æ—Ä–ø—É—Å–∞ –Ω–∞–º–∏ –±—ã–ª–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∞ –æ—á–∏—Å—Ç–∫–∞, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
# 
# –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã, –º–æ–¥–µ–ª—å LightGBM, –æ–±—É—á–µ–Ω–Ω–∞—è —á–µ—Ä–µ–∑ RandomizedSearchCV, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –º–µ—Ç—Ä–∏–∫–æ–π: F1 > 0.75.

# In[ ]:





# ## –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏

# - [x]  Jupyter Notebook –æ—Ç–∫—Ä—ã—Ç
# - [ ]  –í–µ—Å—å –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
# - [ ]  –Ø—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
# - [ ]  –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã
# - [ ]  –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã
# - [ ]  –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75
# - [ ]  –í—ã–≤–æ–¥—ã –Ω–∞–ø–∏—Å–∞–Ω—ã
